---
title: "Model writeup"
author: "Arnie Seong"
date: "`r format(Sys.time(), '%d %B %Y')`"
header-includes:
  - \usepackage{bm}
  - \usepackage{xcolor}
  - \usepackage{amssymb}
output: 
  html_document:
    df_print: paged
  theme: cerulean
  highlight: tango
  toc: yes
  toc_depth: 3
  toc_float:
    collapsed: false
  smooth_scroll: true
  code_fold: show
  urlcolor: blue
params:
  retrain: FALSE
  seed: 314
editor_options: 
  chunk_output_type: console
---
  
  
<style type="text/css">
  
  #TOC>ul>li, h1, h2{
    font-weight: bold;
  }
  
  blockquote{
    background-color: #d5f2f5;
      font-size: small;
  }
  
  b, strong {
    color: #11579e;
  }
  
  caption {
    color: #11579e;
      font-weight: bold;
    font-size: 1.0em;
  }
  
  h1 { font-size: 2em }
  h2 { font-size: 1.6em  }
  h3 { font-size: 1.25em }
  h4 { font-size: 1.10em }
  h5, h6 { font-size: 1em    }
  
  h1, h2, h3 {font-weight: bold;}
  
  a {font-weight: bold; text-decoration: underline}
  
  .nav-pills>li>a:hover, 
  .nav-pills>li>a:focus, 
  .nav-pills>li.active>a,     
  .nav-pills>li.active>a:hover, 
  .nav-pills>li.active>a:focus{
    background-color: #11579e;
  }
  
  .nav-pills{
    background-color: #d5f2f5;
  }
</style>


```{r setup, include=FALSE, message=F, echo=F, warning=F}
# LIBRARIES----

#### plotting:
library(ggplot2)
library(gridExtra)

# #### Misc:
library(here)
library(tidyr)
library(knitr)
library(kableExtra)
library(dplyr)

# model packages
library(torch)

# DOCUMENT SETUP ----
# detect pdf/html output, set chunk options, sci.notation 
latex_out <- knitr::is_latex_output()
knitr::opts_chunk$set(
  cache = FALSE, 
  message = FALSE, 
  echo = !knitr::is_latex_output(), 
  warning = FALSE
)


if (knitr::is_latex_output()) {
  knitr::opts_chunk$set(fig.height=4, 
                        fig.width=6)
} else {
  knitr::opts_chunk$set(out.width = "100%")
}

options(scipen=10)


# TEXT/TABLE FORMATTING----

custom_purple <- ifelse(
  knitr::is_latex_output(),
  "purple",
  "#b51ced"
)

custom_blue <- ifelse(
  knitr::is_latex_output(),
  "blue",
  "#11579e"
)

colorize <- function(x, color=custom_purple) {
  # text color conditional on latex/html output
  # from rmarkdown cookbook
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{ %s}{ %s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color, x)
  } else x
}

cat_color <- function(txt, style = 1, color = 36){
  cat(
    paste0(
      "\033[0;",
      style, ";",
      color, "m",
      txt,
      "\033[0m","\n"
    )
  )  
}

# kable NA handling
options(knitr.kable.NA = '')

# mykable function
mykable <- function(tab, cap,
                    latex_options=c("hold_position", "scale_down", "striped"), 
                    bootstrap_options=c("striped", "hover", "condensed"), 
                    full_width=F, position="center", ...){
  # kable formatting conditional on latex or html output
  if (is.null(getOption("knitr.in.progress"))){
    print(tab)
  } else if (knitr::is_latex_output()){
    kable(x=tab, caption=cap, ...) %>%
      kableExtra::kable_styling(latex_options = latex_options)
  } else if (knitr::is_html_output()){
    kable(x=tab, caption=cap, ...) %>%
      kableExtra::kable_styling(bootstrap_options = bootstrap_options, full_width=full_width, position=position)
  }
}

# notin
`%notin%` <- Negate(`%in%`)

source(here("Rcode", "torch_horseshoe_klcorrected.R"))
source(here("Rcode", "sim_functions.R"))
source(here("Rcode", "analysis_fcns.R"))
```





# Setting:

## data-generating mechanism

We assume a setting in which data is collected on many characteristics $X$, of which only an unknown subset $X^\star \subseteq X$ have any relation (whether linear or not) to the response.  That is, we assume the response $y_i$ is generated by an unknown function $f^\star$ of a subset $X^\star_i$ of the covariate vector $X_i$ such that $f^\star(X^\star_i) = f^\star(X_i)$.  For now, we invoke the usual assumptions of i.i.d. samples and homoskedastic, Gaussian noise.  The assumed data-generating mechanism can be then expressed as

$$y_i \sim N \left( f^\star (X_i), \sigma^2 \right)$$


Our primary goal is to recover the subset of covariates $X^\star$ that account for variation in $y$ while also providing control over false positives via Bayesian FDR.

Our secondary goals include

1. recovering the functional form of relationships between covariates in $X^\star$ and the response;

1. competitive predictive accuracy;

1. uncertainty quantification.




Our idealized setting: 

  - large-ish $n$ (large enough to sustain use of a neural network);
  
  - i.i.d. random sample
  
  - many measured covariates, only a small handful of which actually have an effect on the response;
  
  - normally-distributed, homoscedastic, i.i.d. noise
  
  

## Model

We choose to model $f^\star(X_i)$ using a Bayesian neural network $f_\theta(X_i, W)$ equipped with a group Horsehoe prior on the weights $W$, i.e.

$$\begin{align}
  y_i | W 
  & 
    \sim N\left( f_\theta(X_i, W), \sigma^2 \right)
  \\
  W | z
  & 
    \sim \prod_{j,d} N(w_{j,d} | 0, \lambda_{j}^2 \tau^2)
  \\
\end{align}$$





For each layer $l \in \{1, 2, ..., L\}$, 











## Contributions:

- Few methods exist for controlling false positive rates for variable selection in neural networks;  

- To our knowledge, no previous work has shown control over the Bayesian FDR in Bayesian neural networks;  (need to look at [https://arxiv.org/abs/2510.00875](Molinari, Thoresen 2025 on mirror statistics) more closely)




