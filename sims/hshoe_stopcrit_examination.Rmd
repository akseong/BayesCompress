---
title: "hshoe stopping criteria investigation"
author: "Arnie Seong"
date: "`r format(Sys.time(), '%d %B %Y')`"
header-includes:
  - \usepackage{bm}
  - \usepackage{xcolor}
  - \usepackage{amssymb}
output: 
  html_document:
    df_print: paged
    theme: cerulean
    highlight: tango
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: true
    code_fold: hide
urlcolor: blue
params:
  retrain: FALSE
  seed: 314
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE, message=F, echo=F, warning=F}
# LIBRARIES----

#### plotting:
library(ggplot2)
library(gridExtra)

# #### Misc:
library(here)
library(tidyr)
library(knitr)
library(kableExtra)
library(dplyr)
library(DT)

# DOCUMENT SETUP ----
# detect pdf/html output, set chunk options, sci.notation 
latex_out <- knitr::is_latex_output()
knitr::opts_chunk$set(
  cache = FALSE, 
  message = FALSE, 
  echo = !knitr::is_latex_output(), 
  warning = FALSE
)


if (knitr::is_latex_output()) {
  knitr::opts_chunk$set(fig.height=4, 
                        fig.width=6)
} else {
  knitr::opts_chunk$set(out.width = "100%")
}

options(scipen=10)


# TEXT/TABLE FORMATTING----

custom_purple <- ifelse(
  knitr::is_latex_output(),
  "purple",
  "#b51ced"
)

custom_blue <- ifelse(
  knitr::is_latex_output(),
  "blue",
  "#11579e"
)

colorize <- function(x, color=custom_purple) {
  # text color conditional on latex/html output
  # from rmarkdown cookbook
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{ %s}{ %s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color, x)
  } else x
}

ascii_colorize <- function(txt, style = 1, color = 36){
  paste0(
    "\033[0;",
    style, ";",
    color, "m",
    txt,
    "\033[0m"
  )
}

cat_color <- function(txt, style = 1, color = 36, sep = " "){
  cat(
    ascii_colorize(text, style, color),
    sep = sep
  )  
}

# kable NA handling
options(knitr.kable.NA = '')

# mykable function
mykable <- function(tab, cap,
                    latex_options=c("hold_position", "scale_down", "striped"), 
                    bootstrap_options=c("striped", "hover", "condensed"), 
                    full_width=F, position="center", ...){
  # kable formatting conditional on latex or html output
  if (is.null(getOption("knitr.in.progress"))){
    print(tab)
  } else if (knitr::is_latex_output()){
    kable(x=tab, caption=cap, ...) %>%
      kableExtra::kable_styling(latex_options = latex_options)
  } else if (knitr::is_html_output()){
    kable(x=tab, caption=cap, ...) %>%
      kableExtra::kable_styling(bootstrap_options = bootstrap_options, full_width=full_width, position=position)
  }
}

source(here("Rcode", "torch_horseshoe.R"))
source(here("Rcode", "sim_functions.R"))
```


```{r MISC_FUNCTIONS, echo = FALSE}
`%notin%` <- Negate(`%in%`)

vismat <- function(mat, cap = NULL, lims = NULL, leg = TRUE, na0 = TRUE, square){
  # outputs visualization of matrix with few unique values
  # colnames should be strings, values represented as factors
  # sci_not=TRUE puts legend in scientific notation
  require(ggplot2)
  require(scales)
  require(reshape2)
  
  melted <- melt(mat)
  melted$value <- ifelse(
    melted$value == 0 & na0,
    NA,
    melted$value
  )
  p <- ggplot(melted) + 
    geom_raster(aes(y = Var1, 
                    x = Var2, 
                    fill = value)) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    scale_fill_viridis_c(limits = lims)
  
  if (is.numeric(melted$Var1)){
    p <- p + 
      scale_y_reverse()
  } else {
    p <- p + 
      scale_y_discrete(limits = rev(levels(melted$Var1)))
  }
  
  if (missing(square)) square <- nrow(mat) / ncol(mat) > .9 & nrow(mat) / ncol(mat) < 1.1
  if (square) p <- p + coord_fixed(1)
  
  if (!is.null(cap)) p <- p + labs(title=cap)
  
  if (!leg) p <- p + theme(legend.position = "none")
  
  return(p)
}

```



# Purpose
trying to figure out stopping criteria to use.  Based on 10 simulations of basic linear regression horseshoe architecture (i.e. only 1 neuron):

- 4 covariates truly related to outcome (__linearly related__), 100 nuisance variables.  All generated from N(0, 1) via `torch_randn()`
- N(0,1) noise
- 100 observations in training set, 25 in test set
- true coefficients: -0.5, 1, -2, 4, 0, 0, 0, ....
- only stopping criteria employed was max number of epochs (training epochs = 70k)

# mainline results

```{r}
# combine results files
fname_stem <- here::here("sims", "results", "hshoe_linreg_maxepochs")
sim_seeds <- c()
res_comp <- list()

for (i in 1:10){
  fname <- paste0(fname_stem, i, ".Rdata")
  load(fname)
  sim_seeds <- c(sim_seeds, contents$sim_params$sim_seeds)
  res_comp <- append(res_comp, contents$res)
}

res_comp <- setNames(res_comp, paste0("sim_", 1:length(res_comp)))
final_alphas <- t(sapply(res_comp,
       function(X) X$alpha_mat[nrow(X$alpha_mat),]
       ))
```


## Power


### naive threshold of 0.05

Naive threshold: essentially, is the "dropout rate parameter" $\alpha$ lower than our T1 error threshold.  This interprets $\alpha$ as a probability, which is not great (esp. since $\alpha$ is commonly > 1 for the nuisance variables)

Type II errors:

```{r}
sum(final_alphas[, 1:4] > 0.05)
```

Type II error rate:
```{r}
mean(final_alphas[, 1:4] > 0.05)
```


All errors are from the first covariate ($\beta = 0.5$).  

```{r T2_err}
dt <- DT::datatable(data.frame(round(final_alphas[, 1:4], 3)))
dt %>% formatStyle(1:4, color = styleInterval(0.05, c("black","red")))
```



## Spurious Covariates / T1 error

### naive 0.05 threshold

No spurious covariates chosen setting alpha threshold at 0.05.

```{r T1_err}
sum(final_alphas[, 5:104] < 0.05)
```



## threshold based on posterior-based Wald

A more principled approach might be to compare the dropout parameter $\alpha$ against the inverse of a $\chi^2$ distribution with 1 degree of freedom and applying Bonferroni.  This is based on the idea that

1. (to justify using $\chi^2 (1)$ distribution) the $\alpha$ parameter looks like the inverse of a posterior-based Wald statistic [http://www.mysmu.edu/faculty/yujun/Research/ABT33.pdf](reference - Liu, Li, Yu 2020);  


1. (to justify Bonferroni) the mean-field assumption used in variational inference assumes independence between these parameters.


### posterior Wald:

LLY 2020 propose the posterior-based Wald statistic

<!-- $$\begin{aligned} -->
<!--   T(y, \theta_0)  -->
<!--     & = \int (\theta - \theta_0)'[V_{\theta \theta} (\bar\nu)]^{-1} (\theta - \theta_0) p(\nu | y) d\theta -->
<!--     \\ -->
<!--     & = q_\theta + (\bar\theta - \theta_0)'[V_{\theta \theta} (\bar\nu)]^{-1} (\bar\theta - \theta_0) -->
<!--     \\ -->
<!--     & = q_\theta + W -->
<!-- \end{aligned}$$ -->

$$W = (\bar\theta - \theta_0)'[V_{\theta \theta} (\bar\nu)]^{-1} (\bar\theta - \theta_0) \overset{d}{\rightarrow} \chi^2(q_\theta)$$

- $\theta$ is the parameter(s) of interest ($\bar\theta$ refers to the posterior mean), 

- $q_\theta$ the dimension of $\theta$, 

- $V_{\theta \theta} (\bar\nu)$ the portion of the posterior covariance matrix relevant to $\theta$ ($\nu$ refers to all estimated parameters),


### results for posterior-based Wald interpretation of $\alpha$

#### T2 error

```{r}
wald_thresh <- 1 / qchisq(1 - (0.05 / 104), df = 1)
t2_sum <- sum(final_alphas[, 1:4] > wald_thresh)
t2_sum # T2 errors
```

Results: `r t2_sum` errors total out of a possible 400 (4 true covariates, 100 simulations)

I.e. T2 error rate of `r mean(final_alphas[, 1:4] > wald_thresh)`.


#### T1 error

T1 errors (out of 100 nuisance variables * 100 simulations):

```{r}
sum(final_alphas[, 5:104] < wald_thresh)
```

so a T1 error rate of `r mean(final_alphas[, 5:104] < wald_thresh)`









#### one problem with posterior Wald interpretation:

Below is a histogram of the $\alpha$ parameters, _for the 100 nuisance parameters_,  appearing in the last training epoch of the 100 simulations, followed by a histogram of 1000 draws from a $\chi^2(1)$.

```{r, out.height="60%", out.width="60%"}
hist(1/final_alphas[, 5:104], xlim = c(0, 5), breaks = 250)
hist(rchisq(1000, df=1), xlim = c(0, 5), breaks = 250)
```

The two do not match well.  However, there are a few possible explanations:

1. variational inference is known to underestimate variance (which would push the mode to the right);

1. maybe explaining why there are NO values below 0.7: in LLY 2020, Theorem 3.1, it is clarified that the Bayesian $W$ and the Frequentist $Wald$ are not quite the same:

$$W = Wald + o_p(1) \overset{d}{\rightarrow} \chi^2(q_\theta)$$


Last, we are just looking at the final training epochs.  These simulations simply set a maximum number of 70k training epochs, so it's possible that the network should have trained for a longer period of time.





#### notes / thoughts:

- any way to get ELBOs for competing models to approximate bayes factors?  Is this even useful / desirable?  Avoiding this kind of computation is kind of the reason we're using NN's in the first place....



## Questions: 

- Distribution of alpha?

- Do all the alphas seem to still be decreasing?





s5 <- contents$res$sim_5$alpha_mat[, 2]
s6 <- contents$res$sim_6$alpha_mat[, 2]
s8 <- contents$res$sim_8$alpha_mat[, 2]
s9 <- contents$res$sim_9$alpha_mat[, 2]
df <- data.frame(
  s5, s6, s8, s9,
  "x" = 1:length(s9)
)

df %>% 
  # filter(x > 60) %>% 
  pivot_longer(cols = -"x") %>% 
  ggplot(aes(y = value, x = x, color = name)) + 
  geom_line()



loss_arr <- sapply(contents$res,
                 function(X) X$loss_mat,
                 simplify = "array")
kl_mat <- loss_arr[, 1, ]
tr_mat <- loss_arr[, 2, ]
te_mat <- loss_arr[, 3, ]
sp_mat <- tr_mat - te_mat



kl_roll <- apply(kl_mat, 2, function(X) zoo::rollmean(X, k = 10))
tr_roll <- apply(loss_arr[, 2, ], 2, function(X) zoo::rollmean(X, k = 10))
te_roll <- apply(loss_arr[, 3, ], 2, function(X) zoo::rollmean(X, k = 10))












